{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/autinn/deep-tech-talent/blob/main/Lab06_H_3_convolutional_neural_network_Student_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JgIsB-U1gVW"
      },
      "source": [
        "# **Lab06: Create a Basic Convolutional Neural Network for Image Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvKNe9YXrsn0"
      },
      "source": [
        "## 1. Import Library and Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJn3rJzkb9Ja",
        "outputId": "10abba34-105b-4fbe-eac6-f2b78f06667c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCqIKd873_8g"
      },
      "source": [
        "#@title Code for loading the data\n",
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# utilities library\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import random\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "\n",
        "data_path = '/content/gdrive/My Drive/Colab Notebooks/data/jaffe/jaffe'\n",
        "data_dir_list = os.listdir(data_path)\n",
        "\n",
        "img_data_list=[]\n",
        "img_label = []\n",
        "label_map = {}\n",
        "i = 0\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "    img_list=os.listdir(data_path+'/'+ dataset)\n",
        "    label_map[i] = str(dataset)\n",
        "\n",
        "    # print ('Load the images of dataset-'+'{}\\n'.format(dataset))\n",
        "    for img in img_list:\n",
        "        img_label.append(i)\n",
        "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
        "        input_img_resize=cv2.resize(input_img,(128,128))\n",
        "        img_data_list.append(input_img_resize)\n",
        "    i += 1\n",
        "\n",
        "img_data = np.array(img_data_list)\n",
        "img_data = img_data.astype('float')\n",
        "img_data = img_data/255 #normalization\n",
        "img_label = np.array(img_label)\n",
        "\n",
        "# num_classes = 6\n",
        "# num_of_samples = img_data.shape[0]\n",
        "# img_label = np.ones((num_of_samples,),dtype='int')\n",
        "\n",
        "# img_label[0:29]=0 #30\n",
        "# img_label[30:58]=1 #29\n",
        "# img_label[59:90]=2 #32\n",
        "# img_label[91:121]=3 #31\n",
        "# img_label[122:152]=4 #31\n",
        "# img_label[153:]=5 #30\n",
        "# names = ['ANGRY','DISGUST','FEAR','HAPPY','SAD','SURPRISE']\n",
        "\n",
        "def getlabel(id):\n",
        "    return label_map[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNdwKVdk4EDB"
      },
      "source": [
        "**About this Data**:\n",
        "\n",
        "We will use the Japanese Female Facial Expression (JAFFE) dataset which has 183 images of 10 different female models posing for 6 emotions. The data will be normalized so its value will ranging from 0 to 1.\n",
        "\n",
        "The label will be denoted as numbers, which follow this mapping :\n",
        "\n",
        "|    | Expression   |\n",
        "|---:|:-------------|\n",
        "|  0 | DISGUST          |\n",
        "|  1 | SAD          |\n",
        "|  2 | SURPRISE       |\n",
        "|  3 |   ANGRY    |\n",
        "|  4 |  HAPPY      |\n",
        "|  5 |   FEAR    |\n",
        "\n",
        "<details> <summary>Cite the author</summary>\n",
        "Michael J. Lyons, Shigeru Akamatsu, Miyuki Kamachi, Jiro Gyoba. Coding Facial Expressions with Gabor Wavelets, 3rd IEEE International Conference on Automatic Face and Gesture Recognition, pp. 200-205 (1998). http://doi.org/10.1109/AFGR.1998.670949 Open access content available at: https://zenodo.org/record/3430156\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwqBvQUi4WJs"
      },
      "source": [
        "split the data into train and test set so that we can perform **cross validation** later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA0wzHHI4MMj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(img_data, img_label, test_size=0.1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GvsLxgDrylu"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp9sP0oHr1JM"
      },
      "source": [
        "## 2. Create the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxIABEyz16Q9"
      },
      "source": [
        "In previous two notebook, we already created a similar model using keras. Here's the code if you wanted to remember."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTsugUr11KaC"
      },
      "source": [
        "# simple model in 1st Notebook\n",
        "model_simple = keras.Sequential()\n",
        "model_simple.add(keras.layers.Dense(units=1, input_shape=[1]))\n",
        "\n",
        "model_simple.compile(optimizer='SGD', loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezcE05Ex0YG9"
      },
      "source": [
        "# Neural Network in 2nd Notebook\n",
        "model_nn = keras.Sequential()\n",
        "\n",
        "model_nn.add(keras.layers.Flatten(input_shape=(128,128,3)) ) # flatten layer\n",
        "model_nn.add(keras.layers.Dense(units = 128,activation='relu') )  #input layer\n",
        "model_nn.add(keras.layers.Dense(units = 64, activation='relu') )  # hidden layer\n",
        "model_nn.add(keras.layers.Dense(units = 6, activation='softmax') ) # output layer\n",
        "\n",
        "model_nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZOdssMWyvIH"
      },
      "source": [
        "In this Lab, we will build a simple CNNs to do the image classification. We are now trying to add a convolutional part to our model. Mind the changes compared to previous basic neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K-BEPUOy7qX"
      },
      "source": [
        "model_cnn = keras.Sequential()\n",
        "\n",
        "model_cnn.add(keras.layers.Conv2D(filters=16, kernel_size=(5,5), input_shape=(128,128,3), padding='same', activation=\"relu\"))\n",
        "model_cnn.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation=\"relu\"))\n",
        "model_cnn.add(keras.layers.MaxPooling2D())\n",
        "\n",
        "model_cnn.add(keras.layers.Flatten()) # flatten layer\n",
        "model_cnn.add(keras.layers.Dense(units = 128,activation='relu') )  #input layer\n",
        "model_cnn.add(keras.layers.Dense(units = 64, activation='relu') )  # hidden layer\n",
        "model_cnn.add(keras.layers.Dense(units = 6, activation='softmax') ) # output layer\n",
        "\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1JjuonIRx6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751bdcab-d18e-4d47-90c9-dc5ea7858399"
      },
      "source": [
        "# summarize the model to see what happened inside\n",
        "model_cnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 16)      1216      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16777344  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,791,846\n",
            "Trainable params: 16,791,846\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gle7bAyor6nl"
      },
      "source": [
        "## 3. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcYMhc1u13rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea9b53c-535b-4cbe-9b66-8492ea25b079"
      },
      "source": [
        "model_cnn.fit(x_train, y_train, epochs=20, verbose=1);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 11s 81ms/step - loss: 2.8127 - accuracy: 0.1829\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 1.9084 - accuracy: 0.1951\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 1.6591 - accuracy: 0.3598\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 1.3873 - accuracy: 0.5549\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 1.2012 - accuracy: 0.5122\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.8184 - accuracy: 0.8293\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.5171 - accuracy: 0.8841\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.3425 - accuracy: 0.8963\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.2177 - accuracy: 0.9390\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.2207 - accuracy: 0.9329\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.1317 - accuracy: 0.9695\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0670 - accuracy: 0.9939\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uRG1intr8vS"
      },
      "source": [
        "## 4. Exercise: Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUw3D-OoowYR"
      },
      "source": [
        "# Hints: You can refer to Lab05\n",
        "# Exercise: Select the 7th image in the test set as sample, and pass it to the model to see the classification result\n",
        "\n",
        "# Step 1: select 7-th image as sample\n",
        "\n",
        "\n",
        "# Step 2: Print the original label for the image\n",
        "\n",
        "\n",
        "# Step 3: Plot the image to validate\n",
        "\n",
        "\n",
        "# Step 4: Predict sample image\n",
        "\n",
        "\n",
        "# Step 5: Use np argmax to get the highest number (most activated) of output layer\n",
        "\n",
        "\n",
        "# Step 6: Convert the prediction result to string\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY2P1BrfJaSY"
      },
      "source": [
        "# Comparing Neural Network with CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye70BMHq5fu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31917d41-5372-45c8-8544-d0852d818cce"
      },
      "source": [
        "# train the basic neural network we previously have defined\n",
        "model_nn.fit(x_train, y_train, epochs=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 19.4168 - accuracy: 0.1646\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.1028 - accuracy: 0.1890\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.3149 - accuracy: 0.1890\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.7050 - accuracy: 0.2256\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.1397 - accuracy: 0.2439\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9467 - accuracy: 0.3049\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8385 - accuracy: 0.3598\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7046 - accuracy: 0.3598\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6439 - accuracy: 0.3720\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8436 - accuracy: 0.3354\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9391 - accuracy: 0.2866\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7037 - accuracy: 0.2805\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5431 - accuracy: 0.3902\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5350 - accuracy: 0.3476\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2195 - accuracy: 0.5122\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2427 - accuracy: 0.4756\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1171 - accuracy: 0.5671\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2555 - accuracy: 0.4695\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2733 - accuracy: 0.4573\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3471 - accuracy: 0.4634\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1265 - accuracy: 0.5854\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1403 - accuracy: 0.5427\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0845 - accuracy: 0.6220\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9207 - accuracy: 0.6829\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.0445 - accuracy: 0.6037\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9789 - accuracy: 0.6768\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7957 - accuracy: 0.7073\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.8477 - accuracy: 0.6890\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7681 - accuracy: 0.7317\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9241 - accuracy: 0.6220\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8574 - accuracy: 0.7012\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.7223 - accuracy: 0.7927\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7040 - accuracy: 0.8537\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.7852 - accuracy: 0.6890\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7297 - accuracy: 0.7378\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7468 - accuracy: 0.7256\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6577 - accuracy: 0.7927\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5404 - accuracy: 0.8598\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6164 - accuracy: 0.7744\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.8110\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafb007b510>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWnguy8u5shr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5312fd-b2d2-43f8-e8b4-9949ff4a36dd"
      },
      "source": [
        "score_accuracy = model_nn.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 138ms/step - loss: 1.0247 - accuracy: 0.6316\n"
          ]
        }
      ]
    }
  ]
}